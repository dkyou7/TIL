#### 2강: 선형 배열(Linear Array) (미리보기 가능)

# 선형 배열 (Linear Arrays)

선형 배열은 데이터들이 선 (line) 처럼 일렬로 늘어선 형태를 말합니다. 보통 프로그래밍에서 배열 (array) 이라고 하면 같은 종류의 데이터가 줄지어 늘어서 있는 것을 뜻하는데요, Python 에서는 서로 다른 종류의 데이터 또한 줄세울 수 있는 리스트 (list) 라는 데이터형이 있습니다.

이 강의에서는 같은 종류의 데이터가 줄지어 늘어서 있는 배열을 이용하려 합니다. 앞으로 배열 (array) 이라는 말과 리스트 (list) 라는 말이 자주 등장할 겁니다만, 우선은 같은 것이라고 생각해도 좋지만, 개념적인 구조, 즉 데이터를 늘어놓은 모양새를 말할 때는 배열 (array), Python 의 데이터형을 가리킬 때에는 리스트 (list) 라는 용어를 사용하겠습니다.

또한, 제 7 강부터는 연결 리스트 (linked list) 라는 용어가 등장하게 되는데, 이것과는 구별되어야 합니다. 그것은 그때 가서 다시 얘기하기로 해요.

## Python 리스트에 활용할 수 있는 연산들

### 리스트 길이과 관계 없이 빠르게 실행 결과를 보게되는 연산들

- 원소 덧붙이기 `.append()`
- 원소 하나를 꺼내기 `.pop()`

위 연산들은 리스트의 길이와 무관하게 빠르게 실행할 수 있는 연산들입니다. 리스트의 길이가 아무리 길어도 맨 끝에 요소 하나를 추가하는 것이나 맨 끝 요소 하나를 빼는건 빠르게 할 수 있는 일이죠. 반면, 리스트가 커지면 그에 따라 실행시간이 길어지는 연산들도 있습니다.

### 리스트의 길이에 비례해서 실행 시간이 걸리는 연산들

- 원소 삽입하기 `.insert()`
- 원소 삭제하기 `.del()`

이런 연산들은 리스트의 길이가 길면 길수록 처리가 오래 걸리게 됩니다. 구체적으로 말하면 리스트의 길이예 실행 시간이 비례합니다. 리스트 길이가 100 배가 되면, 위 연산들을 실행하는 데 걸리는 시간도 100 배 커집니다.

### 추가 다른 연산

- 원소 탐색하기: `.index()`

#### 정렬(Sort), 탐색(Search)

# 배열 - 정렬 (sort) 과 탐색 (search)

**이번 강의에서는 lambda (람다) 문법이 등장하므로, 해당 문법에 익숙하지 않다면 잠시 복습을 하고 수강하길 권장합니다.**

정렬과 탐색은 많은 응용에 적용되는, 알고리즘들 중에서도 가장 널리 알려져 있으며 활용도도 높은 것들이라고 할 수 있을 것입니다. 정렬과 탐색을 위한 여러 자료 구조와 알고리즘들이 있지만, 여기에서는 간단하게 선형 배열을 대상으로 정렬과 탐색의 기초를 배워봅니다. 그런데, 선형 배열이 무엇인가요? (잊어버렸다면 지난 강의의 노트를 읽어보는 것도 좋을 겁니다.)

## 정렬(sort) 이란?

복수의 원소로 주어진 데이터를 정해진 기준에 따라 새로 늘어놓는 작업입니다. 정렬 알고리즘에는 여러 종류가 있습니다.

Python 의 리스트 (list) 를 이용한다면, 직접 정렬 알고리즘을 구현할 필요가 없습니다. 왜냐면 이미 리스트 (list) 에 내장된 정렬 기능이 있기 때문인데요, 아래와 같은 서로 다른 두 방법이 대표적입니다.

1. 파이썬 내장 함수 `sorted()`

```python
L2 = sorted(L)
L2 = sorted(L,reverse=True)
```

2. 리스트에 쓸 수 있는 메서드 `.sort()`

```python
L.sort()
L.sort(reverse=True)
```

이 두 방법의 적용이 익숙한가요? 즉, 함수 (function) 와 메서드 (method) 의 차이를 이해할 수 있나요? 만약 그렇지 않다면, 함수와 메서드에 대해서 조금 복습해보는 것도 앞으로의 강의를 이해하는 데 도움이 될 겁니다.

## 수치 (number) 가 아닌 데이터형의 정렬?

이 경우에는 문자열을 사전에 등장하는 순서에 따라 정렬합니다. 문자열의 길이가 더 길다고 해서 더 큰 문자로 취급하는 것이 아닙니다. 단, 차이가 있다면 영어사전에는 대소문자가 섞인 순서로 등장하지만 Python 문자열은 대문자가 소문자에 비해서 무조건 우선합니다. 그렇다면 만약 대소문자 구별을 무시하고 순전히 알파벳 순서에 따라 정렬하려면 어떻게 해야 할까요?

답은 스스로 찾아보기를 권합니다. 만약 잘 모르겠다면, Python 의 문자열 다루기 부분을 복습해보는 것도 좋을 듯하네요.

이 강의에서는 사전 (dictionary) 을 정렬하는 예도 포함합니다. 여러 데이터의 복합으로 이루어진 데이터 원소를 보통 (데이터베이스에서) 레코드 (record) 라고 부르는데요, 레코드를 Python 사전 (dictionary) 으로 표현하고 이것을 정렬하는 방법 또한 알아봅시다!

```python
L = [{'name':'John','score':42},{'name':'Paul','score':52}]

L.sort(key=lambda x:x['score'],reverse=True)

print(L)
```

## 탐색 (search) 이란?

복수의 원소로 이루어진 데이터에서 특정 원소를 찾아내는 작업입니다. 탐색에도 여러 가지 방법이 있지만, 아주 기본적인 두 가지를 소개합니다.

1. 선형 탐색 (linear search), 또는 순차 탐색 (sequential search): 순차적으로 모든 요소들을 탐색하여 원하는 값을 찾아냅니다. 배열의 길이에 비례하는 시간이 걸리므로, 최악의 경우에는 배열에 있는 모든 원소를 다 검사해야 할 수 있습니다. (이런 일은 어떤 원소를 찾으려 할 때 벌어질까요?)
2. 이진 탐색 (binary search): 탐색하려는 배열이 이미 정렬되어 있는 경우에만 적용할 수 있습니다. 배열의 가운데 원소와 찾으려 하는 값을 비교하면, (크기 순으로 정렬되어 있다는 성질을 이용하면) 왼쪽에 있을지 오른쪽에 있을지를 알 수 있습니다 (만약 있긴 있다면). 그러면, 적어도 반대쪽에 없는 것은 확실하므로, 배열의 반을 탐색하지 않고 버릴 수 있습니다. 이 과정을 반복하면 원하는 값을 찾아낼 수 있습니다. 한 번에 절반씩 배열을 잘라나간다면...몇 번이나 이 과정을 반복하게 될까요? (약간의 수학이네요?)

그래서 이진 탐색이 선형 탐색보다 빠른 방법이기는 합니다. 그러나, 뭔가를 찾으려 한다고 할 때, 항상 이진 탐색 방법을 적용하는 것이 답인가요? 그러려면 우선 배열을 정렬해야 한다던데, 크기 순으로 정렬하는 것은 금방 되나요? 한 번만 탐색하고 말 거라면, 굳이 크기 순으로 늘어놓느라 시간을 소모하는 것보다 한번씩 다 뒤지는 것이 낫지 않나요? (물론입니다.)

```python
def solution(L, x):
    lower = 0
    upper = len(L) - 1
    idx = -1
    
    while lower <= upper:
        mid = (lower + upper) // 2
        if x < L[mid]:
            upper = mid - 1
        elif x > L[mid]:
            lower = mid + 1
        else:
            return mid
    return idx
```

#### 4강: 재귀 알고리즘 기초

# 재귀 알고리즘 (recursive algorithms) - 기초

알고리즘들 중에는, 재귀 알고리즘 (recursive algorithm) 이라고 불리는 것들이 있습니다. 이것은 알고리즘의 이름이 아니라 성질입니다. 주어진 문제가 있을 때, 이것을 같은 종류의 보다 쉬운 문제의 답을 이용해서 풀 수 있는 성질을 이용해서, 같은 알고리즘을 반복적으로 적용함으로써 풀어내는 방법입니다.

예를 들면, 1 부터 n 까지 모든 자연수의 합을 구하는 문제 (`sum(n)`)는, 1 부터 n - 1 까지의 모든 자연수의 합을 구하는 문제 (`sum(n - 1)`)를 풀고, 여기에 n 을 더해서 그 답을 찾을 수 있습니다. 즉,

```
sum(n) = sum(n - 1) + n
```

입니다.

생각보다 많은 종류의 문제들이 재귀적으로 (recursively) 풀립니다. 알아볼까요? 그러기 전에!

위의 `sum(n)` 을 구하는 문제를 재귀적으로 해결하기 위해서는, 그 종결 조건 (trivial case) 을 명시해야 합니다. 위 수식 (수학에서는 점화식 이라는 용어를 사용합니다) 이 자연수들의 합을 구하는 문제를 푸는 데 적용될 수 있으려면, 무한히 `n - 1` 까지의 합을 적용해서는 안되고, 언젠가는 이에 대한 답을 주어야 합니다. 어떻게 하나요?

```python
def solution(n):
    if n<=1:
        return 1
    else:
        return n + solution(n-1)
```

그렇습니다. 1 부터 1 까지의 모든 자연수의 합은 1 이므로, 위 점화식에 덧붙여 하나의 수식을 추가해야 합니다: `sum(1) = 1`. 이 두 수식을 묶으면, 1 부터 n 까지의 자연수의 합을 구하는 문제의 답이 됩니다. 이것이 재귀 알고리즘 (recursive algorithm) 입니다.

많은 경우, 재귀적으로 표현된 알고리즘은 사람이 이해하기는 좋지만, 컴퓨터가 알고리즘을 실행하면 그 성능도 좋을까요? 그렇지 않은 경우가 많습니다. 다음 강의인 제 5 강에서 재귀 알고리즘의 예를 추가로 소개하고, 효율성에 대한 논의도 해보기로 합시다.

피보나치 구현

```python
# recursive

def solution(x):
    if x<=1:
        return x
    else:
        return solution(x-1) + solution(x-2)
```

```python
# iterative

def solution(x):
    if x<2:
        return x
    else:
        a,b = 0,1
        for i in range(2,x+1):
            a,b = b,a+b
        return b
```



#### 5강: 재귀 알고리즘 응용

# 재귀 알고리즘 (recursive algorithms) - 응용

얼핏 생각하는 것보다 많은 문제들이 재귀적인 방법으로 풀어집니다. 여기에서는, 아래와 같은 문제들을 재귀 알고리즘으로 풀어보겠습니다.

- 조합의 수 (n 개의 서로 다른 원소에서 m 개를 택하는 경우의 수) 구하기 : nCm

  > n!/m!(n-m)!

```python
def combi(n,m):
    return f(n)/f(m)*f(n-m)
def combi(n,m):
    if n==m:
        return 1
    elif m==0:
        return 1
    else:
	    return combi(n-1,m) + combi(n-1,m-1)
```

- 하노이의 탑 (크기 순서로 쌓여 있는 원반을 한 막대에서 다른 막대로 옮기기)
- 피보나치 순열

문제의 종류에 따라서는 재귀 알고리즘을 적용함으로써 알고리즘을 간단하고 이해하기 쉽게 서술할 수 있다는 장점이 있습니다. 그런데, 문제를 풀어 내는 데 걸리는 시간 측면에서는 어떨까요?

하나의 재귀 알고리즘이 주어질 때, 이것을 재귀적이지 않은 (non-recursive) 방법으로 동일하게 풀어내는 알고리즘이 존재한다는 것을 수학적으로 증명할 수 있습니다. 보통은 순환문 (loop) 을 이용해서 정해진 연산을 반복함으로써 문제의 답을 구하는데, 따라서 반복적 (iterative) 알고리즘이라고 부르기도 합니다. 일반적으로, 주어진 문제에 대해서 반복적인 알고리즘이 재귀적인 알고리즘보다 문제 풀이의 (시간적) 효율이 높습니다.

그럼에도 불구하고, 재귀 알고리즘이 가지는 특성 때문에 트리 (tree) 와 같은 - 제 17 강에서 등장하게 됩니다 - 자료 구조를 이용하는 알고리즘에는 매우 직관적으로 적용할 수 있는 경우가 많습니다. 이 강의에서는 이진 탐색 (binary search) 알고리즘을 재귀적으로 구현하는 빈 칸 채우기 코딩 연습문제를 풀어보기로 합시다.

```python
def binsearch(L,x,lower,upper):
    if lower>upper:
        return -1
    mid = (lower + upper) // 2
    if x == L[mid]:
        return mid
    elif x < L[mid]:
        return binsearch(L, x, mid + 1, upper)
    else:
        return binsearch(L, x, lower, mid - 1)
```



#### 6강: 알고리즘의 복잡도



# 알고리즘의 복잡도 (Comlexity of Algorithms)

물론, 간단한 알고리즘도 있고 복잡한 알고리즘도 있습니다. 하지만, 알고리즘의 복잡도 (complexity) 라고 부르는 것은 문제 풀이의 방식이 얼마나 복잡하냐 단순하냐를 나타내는 말이 아닙니다. 그러면 무엇을 뜻할까요? 이 알고리즘이 실행함에 있어, 문제의 크기 (일반적으로 데이터 원소의 개수를 뜻합니다) 가 커짐에 따라서 얼마나 큰 시간을 (또는 공간을) 요구하느냐를 뜻합니다.

알고리즘의 시간 복잡도는 문제가 커짐에 따라 이 문제를 해결하는 데 소요되는 시간이 어떤 양상으로 증가하는가를 다룹니다. 공간 복잡도는 문제가 커짐에 따라 이 문제를 해결하는 데 소요되는 기억 공간 (메모리) 의 필요가 어떤 양상으로 증가하는가를 다룹니다. 이 강의에서는 알고리즘의 복잡도를 시간 측면에서만 논의하기로 합니다.

알고리즘의 복잡도를 표현하는 데에는 점근 표기법 (asymptotic notation) 을 흔히 이용합니다. 그 중, 특히 big-O notation 이라고 불리는 것을 많이 이용하는데, 영문 대문자 O 를 이용하여 기호로 표현하기 때문에 붙은 이름입니다. 이 표기법은 함수의 증가 양상을 대강 파악할 수 있도록 하는 데 목적이 있는데, 수학적으로 멋지게 정의할 수 있으나 우리는 수학적인 정의는 꺼내지 말기로 합시다. 단, big-O notation 에 대해서는 조금은 알아 둘 필요가 있습니다. 알고리즘의 복잡도를 얘기할 때 흔히 이용되며, 우리 강의에서도 앞으로 반복해서 등장할 것이기 때문입니다.

데이터 원소의 개수가 n 개라고 할 때, O(n) 복잡도를 가지는 알고리즘은 원소의 개수에 비례하여 소요 시간이 증가합니다. 10 개짜리 데이터로 이루어진 문제를 푸는 데 걸리는 시간이 A 라면, 100 개짜리 데이터로 이루어진 문제를 푸는 데 걸리는 시간은 10 * A 입니다. 1,000,000 개짜리 데이터로 이루어진 문제를 푸는 데 걸리는 시간은 100,000 * A 입니다.

그렇다면, O(n2) - 제곱을 표시한 것입니다 - 복잡도를 가지는 알고리즘은 어떠한가요? 알고리즘의 실행 시간이 n 의 제곱에 비례하기 때문에, 10 개짜리 데이터로 이루어진 문제를 푸는 데 걸리는 시간이 B 라면, 100 개짜리 데이터로 이루어진 문제를 푸는 데 걸리는 시간은 100 * B 입니다. 1,000,000 개짜리 데이터로 이루어진 문제는요? 별로 생각하고 싶지 않네요.

하지만, n 의 제곱 (n2) 에 비례하는 복잡도를 가지는 알고리즘은 그나마 복잡도가 낮은 경우입니다. 컴퓨터가 풀어야 하는 많은 문제들이 이보다 더 큰 복잡도를 가집니다. n! (factorial) 에 비례하거나, 2n 에 비례하는 등, 저만큼 높은 복잡도를 가지는 알고리즘은 큰 데이터에 대해서는 현실적으로 적용하여 문제를 풀 수 없는 정도입니다.

좋은 소식은, log(n) 에 비례하거나 n * log(n) 에 비례하는 복잡도를 가지는 알고리즘들도 많이 있다는 것입니다. 우리는 앞으로 이러한 종류의 알고리즘들을 많이 만나보게 됩니다.

#### 7강: 연결 리스트(Linked Lists) (1)



# 연결 리스트 (Linked Lists)

데이터 원소들을 순서를 지어 늘어놓는다는 점에서 연결 리스트 (linked list) 는 선형 배열 (linear array) 과 비슷한 면이 있지만, 데이터 원소들을 늘어놓는 방식에서 이 두 가지는 큰 차이가 있습니다. 구체적으로는, 선형 배열이 번호가 붙여진 칸에 원소들을 채워넣는 방식이라고 한다면, 연결 리스트는 각 원소들을 줄줄이 엮어서 관리하는 방식입니다. 그렇다면, 선형 배열에 비해서 연결 리스트가 가지는 이점은 무엇일까요?

연결 리스트에서는 원소들이 링크 (link) 라고 부르는 고리로 연결되어 있으므로, 가운데에서 끊어 하나를 삭제하거나, 아니면 가운데를 끊고 그 자리에 다른 원소를 (원소들을) 삽입하는 것이 선형 배열의 경우보다 쉽습니다. 여기에서 쉽다 라고 표현한 것은, 빠른 시간 내에 처리할 수 있다는 뜻입니다. 이러한 이점 때문에, 원소의 삽입/삭제가 빈번히 일어나는 응용에서는 연결 리스트가 많이 이용됩니다. 컴퓨터 시스템을 구성하는 중요한 요소인 운영체제 (operating system) 의 내부에서도 이러한 연결 리스트가 여러 곳에서 이용되고 있습니다.

그렇다면, 연결 리스트가 선형 배열에 비해서 가지는 단점은 없을까요? 물론 있습니다. 세상에 공짜는 없는 법이어서, 위에서 말한 바와 같이 원소의 삽입과 삭제가 용이하다는 장점은 거저 얻어지지 않습니다. 생각하기 쉬운 하나의 단점은, 선형 배열에 비해서 데이터 구조 표현에 소요되는 저장 공간 (메모리) 소요가 크다는 점입니다. 링크 또한 메모리에 저장되어 있어야 하므로, 연결 리스트를 표현하기 위해서는 동일한 데이터 원소들을 담기 위하여 사용하는 메모리 요구량이 더 큽니다. 그보다 더 우리의 관심을 끄는 단점은, k 번째의 원소 를 찾아가는 데에는 선형 배열의 경우보다 시간이 오래 걸린다는 점입니다. 선형 배열에서는 데이터 원소들이 번호가 붙여진 칸들에 들어 있으므로 그 번호를 이용하여 대번에 특정 번째의 원소를 찾아갈 수 있는 데 비하여, 연결 리스트에서는 단지 원소들이 고리로 연결된 모습을 하고 있으므로 특정 번째의 원소를 접근하려면 앞에서부터 하나씩 링크를 따라가면서 찾아가야 합니다.

이 강의에서는, 몇 종류의 연결 리스트들 중에서 가장 단순한 형태인 단방향 연결 리스트 (singly linked list) 를 추상적 자료 구조로 정의하고, 이 추상적 자료 구조에 가할 수 있는 아래와 같은 연산들을 배웁니다.

- 특정 원소 참조 (k 번째)
- 리스트 순회 (list traversal)
- 길이 얻어내기

다음 강의에서는 위에 나열한 연산들 이외에, 연결 리스트에서 핵심이라고 할 수 있는 원소의 삽입/삭제 등을 포함한 추가의 연산들을 배우게 됩니다. 물론, 이 자료 구조의 표현과 연산의 구현은 Python 예제로 이루어져 있습니다.

#### 8강: 연결 리스트(Linked List) (2)



이번 강의에서는 원활한 내용 이해를 위한 소스코드를 배포합니다. [여기를 눌러](https://s3.ap-northeast-2.amazonaws.com/grepp-cloudfront/programmers_imgs/learn/course57/08+-+linkedlist.py) linkedlist.py 파일을 다운받으세요.

# 연결 리스트 (Linked Lists)

연결 리스트의 두 번째 강의입니다. 여기에서는, 연결 리스트의 핵심 연산으로서 아래와 같은 것들이 등장합니다.

- 원소의 삽입 (insertion)
- 원소의 삭제 (deletion)
- 두 리스트 합치기 (concatenation)

앞서 제 7 강에서 언급한 바와 같이, 이러한 연산이 쉽게 (빠르게) 이루어질 수 있다는 점이 연결 리스트가 선형 배열에 비하여 가지는 특장점입니다. 조금 다르게 표현하면, 이런 연산들이 빨라야 하는 응용처에 적용하기 위함이 연결 리스트의 존재 이유입니다.

그런데, 나열된 데이터 원소들의 사이에 새로운 데이터 원소를 삽입하려면, 앞/뒤의 원소들을 연결하고 있는 링크를 끊어 내고, 그 자리에 새로운 원소를 집어넣기 위해서 링크들을 조정해 주어야 하는, 프로그래머로서는 아주 조금 귀찮은 일들이 수반됩니다. 이 강의에서는 그러한 작업들을 Python 코드로 작성하는 연습을 함으로써 자료 구조를 다루는 프로그래밍 기법의 기초를 익힙니다. 이 기법들은 이후에 조금씩 더 복잡해지는 자료 구조를 프로그램으로 구현하는 데 바탕이 될 것입니다. 늘 그렇듯, 프로그래밍에서 어려운 점은 특이한 경우들에 대해서도 고려해야 한다는 점인데요, 원소의 삽입에 있어서는 맨 앞 또는 맨 뒤에 새로운 원소를 삽입하는 경우가 조금 생각할 꺼리가 되는 일입니다.

마찬가지로, 원소의 삭제에 있어서도 맨 앞 또는 맨 뒤의 원소를 삭제하는 경우가 조금 신경써서 처리할 일들이 생기는 경우들입니다. 이 내용은 동영상 강의에서 자세히 설명하고, 연습문제를 통한 코딩 실습으로 구현 능력을 키우도록 합니다.

마지막으로, 두 리스트를 합치는 일은 생각보다 훨씬 쉽습니다. 눈치가 빠른 분들은 이것이 매우 간단하리라는 것을 (제 7 강을 공부하셨다면) 쉽게 알아차리셨을 것 같네요.

연결 리스트를 다루는 프로그래밍 연습을 해보면서, 두 가지를 염두에 두시기를 바랍니다. 첫째, 이것이 무엇을 위함이냐? 즉, 연결 리스트라는 자료 구조를 착안함으로써 어떤 목적을 이루고자 했는지, 다시 말하면 연결 리스트가 가지는 장점이 어떤 곳에서 발휘되는지, 알고리즘의 복잡도 (제 6 강을 참고하세요) 측면에서 생각해보시기 바랍니다. 둘째, 링크를 조정하는 등의 코딩은 앞으로 나타나게 될 트리 (tree) 라든지, 이 강의 시리즈에서 다루지는 않지만 그래프 (graph) 등을 프로그래밍할 때를 대비한 연습이 된다는 점을 떠올리시고, 이런 종류의 코딩에 익숙해지려 노력해 보시기 바랍니다.

#### 9강: 연결 리스트(Linked Lists) (3)



이번 9강에 필요한 파일인 linkedlist.py 는 [여기를 눌러](https://s3.ap-northeast-2.amazonaws.com/grepp-cloudfront/programmers_imgs/learn/course57/09+-+linskedlist.py) 다운받으세요. (8강의 파일과 다릅니다)

# 연결 리스트 (Linked Lists)

연결 리스트의 세 번재 강의입니다. 여기에서는, 진짜로 연결 리스트가 힘을 발휘하는 경우에 대해서 진지하게 생각해보기로 합니다. 리스트를 따라서 하나 하나 원소들을 대상으로 어떤 작업을 하다가, 그 위치에 새로운 데이터 원소를 삽입하거나, 아니면 그 위치에 있는 데이터 원소를 삭제하는 경우입니다. 앞의 강의 (제 8 강) 에서는 설명을 명확히 하고 프로그래밍 연습을 쉽게 하기 위해서 특정 번째 를 지정하여 원소를 삽입/삭제하는 연산을 정의하고 코딩으로 구현해보았는데요, 여기에서는 특정 원소의 바로 다음 을 지정하여 원소를 삽입/삭제하는 연산을 정의하고 구현해봅니다.

그러자면, 맨 앞에 원소를 추가 (삽입) 하거나 맨 앞의 원소를 제거 (삭제) 하는 연산을 지정하기가 좀 애매해지는군요. 이런 경우에도 동일한 방법을 적용하기 위해서, 이번에는 연결 리스트의 맨 앞에다가 데이터 원소를 담고 있지 않은, 그냥 자리만 차지하는 노드 (node - 이제는 이런 용어에는 익숙하지요?) 를 추가한, 조금 모습이 달라진 연결 리스트를 정의합니다.

이렇게 맨 앞에 추가된, 데이터 원소를 담고 있지 않은 노드를 더미 노드 (dummy node) 라고 부릅니다. 더미 노드를 가지는 연결 리스트를 대상으로, 지금까지 우리가 정의한 아래와 같은 연산들을 구현해봅니다.

- 길이 얻어내기
- 리스트 순회 (traversal)
- 특정 원소 참조 (k 번째)
- 원소 삽입 (insertion)
- 원소 삭제 (deletion)
- 두 리스트 합치기 (concatenation)

동영상 강의와 연습문제를 통해서 명백해지겠지만, 앞의 두 강의 (제 7 강과 제 8 강) 내용을 잘 이해하고 있다면, 이런 식으로 연결 리스트의 구조를 조금 확장하는 것은 코드를 아주 조금 수정함으로써 쉽게 할 수 있음을 발견하게 됩니다. 이번에도 역시, 원소의 삭제는 동영상 강의의 설명을 충분히 숙지하신 뒤에 연습문제로 풀어보세요.

#### 10강: 양뱡향 연결 리스트(Doubly Linked Lists)



이번 강의를 위해 필요한 doublylinkedlist.py 파일은 [여기를 눌러](https://s3.ap-northeast-2.amazonaws.com/grepp-cloudfront/programmers_imgs/learn/course57/10+-+doublylinkedlist.py) 다운받으세요.

# 양방향 연결 리스트 (Doubly Linked Lists)

연결 리스트에 관한 마지막 강의입니다. 지금까지의 연결 리스트에서는 링크가 한 방향으로, 즉 앞에서 뒤로, 다시 말하면 먼저 오는 데이터 원소를 담은 노드로부터 그 뒤에 오는 데이터 원소를 담은 노드를 향하는 방향으로만 연결되어 있었습니다. 여기에서는 새로운 (조금 다른?) 연결 리스트로서 양방향 연결 리스트 (doubly linked list) 를 소개합니다.

말 그대로, 양방향 연결 리스트에서는 노드들이 앞/뒤로 연결되어 있습니다. 즉, 인접한 두 개의 노드들은 앞의 노드로부터 뒤의 노드가 연결되어 있을뿐만 아니라, 뒤의 노드로부터 앞의 노드도 연결되어 있습니다. 한 노드의 입장에서 보자면, 자신보다 앞에 오는 노드를 연결하는 링크와 자신보다 뒤에 오는 노드를 연결하는 링크를 둘 다 가집니다. 따라서 모든 연결은 양방향으로 이루어져 있으며, 그러한 이유로 이런 구조의 연결 리스트를 양방향 연결 리스트 라고 부릅니다.

양방향 연결 리스트는 단방향 연결 리스트에 비해서 어떤 단점을 가지나요? 당연히, 링크를 나타내기 위한 메모리 사용량이 늘어납니다. 또한, 원소를 삽입/삭제하는 연산에 있어서 앞/뒤의 링크를 모두 조정해 주어야 하기 때문에 프로그래머가 조금 더 귀찮아집니다. 그럼에도 불구하고 왜 양방향 연결 리스트를 이용할까요? 당연히, 장점들이 있기 때문이겠죠?

양방향 연결 리스트가 단방향 연결 리스트에 비해서 가지는 장점은, 데이터 원소들을 차례로 방문할 때, 앞에서부터 뒤로도 할 수 있지만 뒤에서부터 앞으로도 할 수 있다는 점입니다. 너무 당연한가요? 하지만, 실제로 (제 7 강에서 언급한 바와 같이) 컴퓨터 시스템의 주요 구성 요소의 하나인 운영체제 (operating system) 등에서는 리스트를 대상으로 앞/뒤로 왔다 갔다 하면서 작업을 행하는 일들이 빈번히 요구되고, 따라서 양방향 연결 리스트가 많이 이용되고 있습니다.

제 9 강에서 했던 것과 마찬가지로, 동일한 모습의 연산을 일관되게 적용하기 위해서는 양방향 연결 리스트의 맨 앞과 맨 뒤에 더미 노드 (dummy node) 를 하나씩 추가할 수 있습니다. 링크를 앞/뒤로 두고, 더미 노드도 맨 앞과 맨 뒤에 두고, 점점 리스트의 모습이 복잡해져 가는 것처럼 느껴지나요? 그러나, (실습을 통해서 느끼게 될 것입니다만) 이렇게 함으로써 오히려 리스트를 대상으로 하는 연산들이 깔끔하게 구현될 수 있다는 장점 - 다시 말하면, 작성해야 하는 코드의 양이 조금 늘어나더라도 코딩은 좀 더 쉬워진다는 - 이 생깁니다. 특별한 경우로 처리해야 하는 것들이 없어지기 (줄어들기) 때문입니다. 이번에는, 아래와 같은 연산들을 모두 연습문제로 풀어보면서 양방향 연결 리스트가 매우 유연한 자료 구조라는 느낌을 받아보시기 바랍니다.

- 리스트 순회 (traversal)
- 원소 삽입 (insertion)
- 원소 삭제 (deletion)
- 리스트 병합 (concatenation)

#### 11강: 스택(Stacks)



원활한 수강을 위해 stacks.py 파일이 필요합니다. [여기를 눌러](https://s3.ap-northeast-2.amazonaws.com/grepp-cloudfront/programmers_imgs/learn/course57/11+-+stacks.py) 다운받으세요.

# 스택 (Stacks)

마치 접시를 차곡차곡 쌓았다가 맨 위의 접시부터 다시 꺼내어 사용하는 것처럼, 추가된 데이터 원소들을 끄집어내면 마지막에 넣었던 것부터 넣은 순서의 역순으로 꺼내지는 자료 구조를 스택 (stack) 이라고 부릅니다. 이처럼 마지막에 넣은 것이 가장 먼저 꺼내어지는 성질 때문에 스택을 다른 말로는 후입선출 (LIFO; last-in first-out) 자료 구조라고도 합니다.

스택에 데이터 원소를 추가하는 (집어넣는) 동작을 푸시 (push) 연산이라고 하고, 마지막에 추가되었던 원소를 참조하고 삭제하는 (꺼내는) 동작을 팝 (pop) 연산이라고 합니다. 스택은 이 두 연산을 제공하는 간단한 자료 구조인데, 여러 가지의 알고리즘을 구현하는 데 있어서 활용도가 높습니다. 예를 들어, 컴퓨터 내부에서 프로그램이 실행할 때 함수 호출이 일어나고 함수들이 리턴하면 마지막 호출된 곳으로 돌아가는 동작을 구현하는 데에도 스택이 이용되고, 이러한 일은 컴퓨터의 동작에 핵심적인 것이기 때문에 컴퓨터 하드웨어 (프로세서) 는 어떤 방식으로든 스택을 내부적으로 관리하는 기능을 갖고 있습니다. 이것을 떠올려보려면, 제 4 강과 제 5 강에서 배웠던 재귀 함수 가 줄줄이 호출되었다가 줄줄이 리턴하는 모습을 생각해보세요.

컴퓨터 내부에서뿐만 아니라, 응용 프로그램을 작성하는 데에도 스택을 활용하면 잘 풀어낼 수 있는 종류의 문제들이 많이 있습니다. 스택을 이용하는 알고리즘의 예를 다음 (제 12 강) 과 그 다음 (제 13 강) 에서 맞이하게 됩니다.

이 강의에서는, 먼저 스택이 어떻게 동작하는지를 이해하고, 이후에 이용할 수 있도록 스택을 추상적 자료 구조로 구현해봅니다. 스택을 구현하는 데에는 이미 우리가 알고 있는 선형 배열을 이용할 수도 있고, 앞서 몇 차례의 강의에서 다룬 연결 리스트를 이용할 수도 있습니다. 이처럼, 기본적인 자료 구조는 또다른 자료 구조를 만드는 데 재료로 이용되기도 합니다. 두 가지 방식으로 스택을 구현해보는데, 아래와 같은 연산들을 제공하기로 합니다.

- `size()`: 현재 스택에 들어 있는 데이터 원소의 수를 구함
- `isEmpty()`: 현재 스택이 비어 있는지를 판단 (`size() == 0?`)
- `push(x)`: 데이터 원소 `x` 를 스택에 추가
- `pop()`: 스택에 가장 나중에 저장된 데이터 원소를 제거 (또한, 반환)
- `peek()`: 스택에 가장 나중에 저장된 데이터 원소를 참조 (반환), 그러나 제거하지는 않음

연습문제에서는 스택을 이용하는 간단한 알고리즘으로서 수식의 괄호가 올바르게 구성되어 있는지를 판단하는 코드를 작성해봅니다.

#### 12강: 수식의 후위 표기법



# 스택의 응용 - 수식의 후위 표기법 (Postfix Notation)

이번 강의와 다음 강의에서는, 지난 강의 (제 11 강) 에서 마련한 스택을 이용하여 문제를 풀어내는 예제를 소개합니다. 이 예제는 4칙연산 (더하기 `+`, 빼기 `-`, 곱하기 `*`, 나누기 `/`) 과 괄호로 이루어진 수식이 주어졌을 때 연산의 우선순위를 지키면서 이 수식의 값을 계산하는 알고리즘입니다. 그러기 위해서 수식의 후위 표기법 (postfix notation) 이라는 것을 이용합니다.

우리가 일상에서 사용하는 수식의 표기법은, 중위 표기법 (infix notation) 이라고 부를 수 있습니다. 두 개의 피연산자 `A` 와 `B` 를 가지고 덧셈을 하는 수식을 표기하면 `A + B` 와 같이 되는데, 이 때 연산자인 `+` 가 두 피연산자의 사이에 (가운데에) 위치하기 때문에 중위 표기법이라고 부릅니다. 그렇다면 후위 표기법이란 무엇일까요? 연산자를 두 피연산자의 뒤에 쓰는 방식입니다. 따라서 앞의 예인 `A + B` 를 후위 표기법으로 표기하면 `AB+` 가 됩니다.

후위 표기법을 이용하면, 괄호를 쓰지 않고도 연산의 우선순위를 수식에 표현할 수 있습니다. 예를 들어, 중위 표기법으로 표기된 `(A + B) * (C + D)` 를 후위 표기법으로 변환하여 쓰면

```
A B + C D + *
```

와 같이 표현됩니다. `A` 와 `B` 를 가장 먼저 덧셈하고, `C` 와 `D` 또한 덧셈한 뒤, 마지막으로 그 두 결과를 곱한다는 뜻입니다. 그렇다면, `A + B * C` 를 후위 표기법으로 변환하면 어떻게 될까요?

```
A B C * +
```

가 됩니다. (`A`) 와, (`B` 와 `C` 의 곱) 을 더한다는 의미가 됩니다.

이렇게 수식을 후위 표기법으로 표기하면, 컴퓨터가 (프로그램이) 수식을 계산하는 데 유리 (편안) 해집니다. 왼쪽부터 수식을 읽으면서 연산자를 만날 때마다 두 피연산자에 그 셈을 적용하면 되기 때문인데요, 이 때 스택이 이용됩니다.

이 강의에서는 문자열로 주어진 중위 표기법 수식을 후위 표기법 수식으로 변환하는 알고리즘을 소개합니다. 이 때에도 스택이 이용됩니다. 다시 말하면, (1) 중위 표기법으로 쓰인 수식을 후위 표기법으로 변환하고, (2) 후위 표기법으로 쓰인 수식을 계산하는 두 단계를 거치게 되는데, 그 두 단계에서 각각 스택을 활용합니다.

이번 강의에서는 위 (1) 을 행하는 알고리즘을 설계하고, 스택을 어떻게 활용하는지를 설명합니다. 실제로 주어진 수식을 후위 표기법으로 변환하는 코드는 연습문제를 통하여 직접 작성해보세요.

#### 13강: 후위 표기 수식 계산



앞서 제 12 강에서는 중위 표기법으로 표현된 4칙연산 수식을 후위 표기법으로 변환하는 알고리즘을 스택을 활용하여 구현해보았습니다. 이번에는, 이렇게 후위 표기법으로 표현된 수식의 값을 계산 (evaluate) 하는 알고리즘을 설계하고 구현해봅니다.

수식의 계산을 행하는 알고리즘은 앞선 강의에서 배운 후위 표기법으로 수식을 변환하는 알고리즘보다 더 쉽게 이해할 수 있습니다. (보다 직관적입니다.) 말로만 설명해보면,

- 수식을 왼쪽부터 시작해서 오른쪽으로 차례대로 읽어들이면서
- 피연산자가 나타나면, 스택에 넣어 둔다.
- 연산자가 나타나면, 스택에 들어 있는 피연산자를 두 개 꺼내어 연산을 적용하고, 그 결과를 다시 스택에 넣어 둔다.

를 반복하면 마지막에 모든 연산이 적용된 결과가 스택에 (유일하게) 남아 있게 됩니다. 앞선 강의 (제 12 강) 에서 소개한 예제 수식을 이용해서도 한번 연필과 종이를 이용해서 손으로 시뮬레이션 해보시고, 조금 더 복잡한 수식을 각자 예제로 선정하여 동일한 시뮬레이션 을 해보시기 바랍니다. 이렇게 손으로 시뮬레이션 을 해보면, 무턱대고 코딩에 달려드는 것보다 알고리즘의 동작을 더 이해할 수 있으니까요.

연습문제에서는, 문자열로 주어진 수식을 우선 중위 표기법으로부터 후위 표기법으로 변환하고 (스택 이용), 이 결과 후위 표현식을 계산하는 (스택 이용) 코드를 작성하도록 되어 있습니다. 문자열로 쓰인 숫자를 실제 정수 데이터로 변환하는 과정 등이 조금 귀찮기는 하지만, 좋은 코딩 연습이 될 것이므로 전체 코드를 잘 이해하도록 해보십시오. 코드를 완성하고 나면, 이 강의 시리즈를 통해서 연습으로 구현한 코드 중에서는 처음으로 (조금이나마) 쓸모가 있는 코드가 얻어져 있을 것입니다.

#### 14강: 큐(Queues)



# 큐 (Queues)

스택 (stack) 과 더불어 매우 빈번하게 이용되는 자료 구조가 큐 (queue) 입니다. 큐 또한 데이터 원소를 한 줄로 늘어세우는 자료 구조, 즉 선형 (linear) 구조라는 점에서는 지금까지 배워온 선형 배열, 연결 리스트, 그리고 스택과 마찬가지입니다만, 스택과는 어떻게 보면 반대인 특성을 가지고 있습니다.

스택에 자료를 넣고 꺼내는 원칙을 기억하나요? 어느 시점에서 스택에 들어 있는 데이터 원소를 꺼내면, 그 이전에 가장 마지막에 넣었던 원소가 꺼내집니다. 이러한 특징을 후입선출 (LIFO; last-in first-out) 이라고 부른다는 것도 제 11 강에서 언급한 바 있습니다.

큐에서는 스택과는 반대로, 어느 시점에서 큐에 들어 있는 데이터 원소를 꺼내면 큐에 들어 있는 원소들 중 가장 먼저 넣었던 것이 꺼내집니다. 따라서 큐를 선입선출 (FIFO; first-in first-out) 이라고도 부릅니다. 실제로, 스택을 일컬어 후입선출이라고 하는 경우보다는 그냥 스택이라고 많이 부르는데, 큐는 파이포 라고도 많이 부릅니다. 이러한 선입선출 구조를 머리 속에 떠올려 보면, 긴 대롱이 있고 한 쪽 끝에서는 내용을 (데이터 원소를) 집어넣고 다른 쪽 끝에서는 꺼내어 쓰는 모양새로 생각할 수 있겠네요.

데이터 원소를 큐에 넣는 동작을 인큐 (enqueue) 연산이라고 부르고, 반대로 큐로부터 데이터 원소를 꺼내는 동작을 디큐 (dequeue) 연산이라고 부릅니다. 이 두 가지 핵심 연산을 포함한 큐의 추상적 자료 구조를, 여느 때와 마찬가지로 Python 코드로 구현해보려 합니다. 스택의 경우에도 그랬지만, 큐의 경우에도 이것을 구현하기 위하여 선형 배열을 이용할 수도 있고 연결 리스트를 이용할 수도 있습니다.

그런데, 선형 배열을 이용한 연결 리스트에서는 디큐 연산이 큐의 길이에 비례하는 만큼의 시간을 소요합니다. 배열에 저장된 데이터 원소들을 하나하나 앞 칸으로 당겨서 위치를 조정해야 하기 때문입니다. 그래서 연산의 시간 복잡도 측면에서는 연결 리스트로 큐를 구현하는 것이 유리합니다. 연습문제에서는 제 10 강에서 배운 (그리고 코드도 마련한) 이중 연결 리스트를 이용하여 큐를 구현하는 실습을 합니다.

#### 15강: 환형 큐(Circular Queue)



# 환형 큐 (Circular Queues)

큐 (queue) 또한 스택과 마찬가지로 컴퓨터 시스템을 구성하는 많은 곳에서 이용됩니다. 우리의 실습 범위에 포함되지 않기는 하지만, 예를 들어 살펴볼까요? 어느 컴퓨터 시스템에서 서로 다른 응용 프로그램들이 프린터에 인쇄할 문서를 보낸다고 생각해봅시다. 시스템 (보다 명확하게는 운영체제) 내에서는 프린팅 큐라는 자료 구조를 유지하여 프린터에 보내진 인쇄할 문서들을 유지할 수 있습니다. (대기열 이라는 말이 이런 모습을 잘 설명하겠네요.) 또 다른 예로는, 네트워크 인터페이스를 통하여 도착하는 패킷 (packet) 들도 큐에 쌓아서 도착한 순서대로 적절한 응용 프로그램에게 데이터를 보내주는 기능을 운영체제 내에서는 구현하고 있을 수 있겠네요.

그런데, 큐에 담을 수 있는 데이터의 양 (우리 강의에서 이용하는 용어를 가져다 쓰자면, 데이터 원소의 개수) 이 무한할 수는 없을 것입니다. 만약 큐에 담을 수 있는 원소의 개수의 상한을 미리 정하고 이를 지킬 수 있다면, 선형 배열을 이용해서 큐를 효과적으로 구현할 수 있습니다. 선형 배열의 한쪽 끝과 다른 쪽 끝이 서로 맞닿아 있는 모습 (원형 또는 환형) 으로 생각하고, 큐의 맨 앞과 맨 뒤를 가리키는 (즉, 원소를 넣을 쪽의 배열 인덱스와 꺼낼 쪽의 배열 인덱스를) 기억해 두면, 데이터 원소가 빠져 나간 쪽의 저장소를 재활용하면서 큐를 관리할 수 있습니다.

이러한 모습으로 구성한 큐를 환형 큐 (circular queue) 라고 부릅니다. 이 강의에서는 환형 큐의 운용에 대하여 배워보고, 연습문제로 환형 큐를 추상적 자료구조로 구현해봅니다.

환형 큐를 구현하는 데에도 선형 배열을 이용하거나 연결 리스트를 이용할 수 있을까요? 물론입니다. 그런데, 이 강의에서는 환형 큐를 구현함에 있어 선형 배열을 이용하는 예제만을 소개합니다. 왜 그럴까요? 선형 배열과 연결 리스트의 장단점을 상기하시고, 환형 큐를 만드는 데 있어서 어떤 장점을 택해야 할지를 생각해보면 이에 대한 답은 자명할 것입니다. 각자 생각해보시고, 만약 굳이 연결 리스트를 이용해서 환형 큐를 구현한다면 어떻게 하면 좋을지에 대해서도 연습 삼아 생각해보시면 좋을 것 같네요.

#### 16강: 우선순위 큐(Priority Queues)



# 우선순위 큐 (Priority Queues)

지금까지 (제 14 강과 제 15 강에서) 배운 큐들은, 먼저 들어간 원소가 먼저 나온다는 원칙, 즉 선입선출 (FIFO; first-in first-out) 원칙이 그대로 적용된 것들이었습니다. 그런데, 경우에 따라서는 이 원칙을 지키기보다는 원소들 사이의 우선순위 (priority) 관계에 따른 순서로 원소들이 꺼내어지는 응용이 필요하기도 합니다. 큐에 원소를 추가하는 연산은 다른 점이 없되, 큐에서 원소를 꺼내는 원칙은 원소들 사이의 우선순위에 따르는 자료구조로서 우선순위 큐 (priority queue) 라는 것을 소개합니다. 대표적인 응용 예를 들자면, 운영체제에서 CPU 스케줄러를 구현할 때, 현재 실행할 수 있는 작업들 중 가장 우선순위가 높은 것을 골라 실행하는 알고리즘같은 것을 들 수 있겠네요.

우선순위 큐를 구현하는 데에는 두 가지의 서로 다른 접근 방법을 생각할 수 있습니다. 단순한 얘기이지만, 아래와 같은 것들이겠네요.

1. 큐에 원소를 넣을 때 (enqueue 할 때) 우선순위 순서대로 정렬해 두는 방법
2. 큐에서 원소를 꺼낼 때 (dequeue 할 때) 우선순위가 가장 높은 것을 선택하는 방법

어느 쪽이 더 좋을 것이라고 생각하나요? 또한, 우선순위 큐를 구현하는 재료로서, 이미 배운 것들 중 선형 배열을 선택할 수도 있고 연결 리스트를 선택할 수도 있습니다. 어느 것을 선택하는 것이 더 유리할까요?

이 강의에서는 양방향 연결 리스트를 선택하여 우선순위 큐를 구현하기로 하고, 원소를 추가할 때 우선순위에 따른 알맞은 자리를 찾아서 정렬된 형태로 유지해 두고 꺼낼 때 한 쪽 끝에서 꺼낼 수 있도록 코드를 만들어봅니다. 이렇게 하면, 원소를 넣는 (enqueue) 연산의 복잡도는 `O(n)` 으로서 큐의 길이에 비례하고, 원소를 꺼내는 (dequeue) 연산의 복잡도는 `O(1)` 로서 상수 시간, 즉 데이터 원소의 개수에 무관한 시간이 걸립니다. 실제 코드를 보면서 (빈칸 채우기 연습문제입니다) 정말 그런지 확인해보시기 바랍니다.

그렇다면, 위에서 말한 다른 방법들 (선형 배열을 이용하거나, 아니면 큐에 원소를 넣을 때는 그냥 한쪽에서 순서대로 집어넣고 꺼낼 때 가장 높은 우선순위의 것을 고르는 방식을 적용하거나) 을 선택하면 각각 enqueue 와 dequeue 연산에서 얼마나 유리하거나 얼마나 불리할까요? 큰 차이는 아닐 수 있지만, (1) 알고리즘의 복잡도와 (2) 구현의 편의성 두 가지 측면에서 비교해보시기 바랍니다.

마지막으로, 우선순위 큐는 나중에 (제 23 강에서) 배울 예정이지만, 조금 다른 자료 구조를 이용하여 더욱 효율적으로 구현할 수 있습니다. 트리 (tree) 라고 불리는 자료 구조를 도입하여 가능해지는 일인데요, 다음 강의부터는 트리에 대해서 배워보도록 하겠습니다.

#### 17강: 트리(Trees)



# 트리 (Trees)

데이터의 검색과 탐색에 아주 널리 이용되는 자료 구조로서 트리 (tree) 라는 것이 있습니다. 우리 말로 나무 라고 번역하기도 하는데, 대부분의 경우에는 그냥 트리 라고 부릅니다. 이번 강의에서부터 끝 (제 23 강) 까지는 모두 트리의 추상적 자료 구조 표현과 트리를 이용하는 알고리즘들을 다룹니다. 물론, 여기에서 소개되지 않는 수많은 트리들이 고안되어 왔고, 이러한 트리들은 데이터베이스 시스템 또는 검색 엔진 등에서 아주 많이 이용됩니다. 우리는 트리의 기초적인 사항을 익히고, 간단한 트리 몇 가지를 추상적 자료 구조로 구현하는 연습을 해보겠습니다.

트리를 딱딱하게 말하면, 순환하는 길이 없는 그래프 (graph) 로 정의합니다. 그럼 그래프란 무엇인가요? 이에 대해서는 우리 강의의 범위 내에서는 다루지 않습니다만, 제 23 강까지 공부를 끝낸 다음에 자료 구조와 알고리즘을 더 공부한다면 곧이어 만나게 되는 구조입니다. 특히 이산수학 (discrete mathematics) 이라는 수학 분야에서 많이 다룹니다.

그러나, 우리 강의에서는 그래프를 다루는 데까지는 가지 않기 때문에, 좀 모호하더라도 보다 단순하게 설명할 필요가 있겠습니다. 트리란, 뿌리 (루트; root) 노드에서 간선 (edge) 들이 마치 나무에서 뿌리로부터 잔가지로 뻗어나가듯이 가지치기된 구조를 말합니다. 보통은 트리를 그림으로 표시할 때 루트가 윗쪽에 오도록 그리기 때문에, 마치 나무를 위 아래를 뒤집어 놓은 듯한 모양을 흔히 생각하게 됩니다.

이번 강의에서는, 이후 트리에 대한 학습의 바탕을 마련하기 위해서, 아래와 같은 용어들이 무슨 뜻인지를 배웁니다.

- 노드 (nodes)
- 간선 (edges)
- 루트 노드 (root node), 리프 노드 (leaf nodes), 내부 노드 (internal nodes)
- 부모 (parent) 노드와 자식 (child) 노드
- 노드의 수준 (level)
- 노드의 차수 (degree)
- 트리의 높이 (height) - 또는, 깊이 (depth) -
- 부분 트리 (서브트리; subtrees)
- 이진 트리 (binary trees)
- 포화 이진 트리 (full binary trees)
- 완전 이진 트리 (complete binary trees)

앞으로 트리를 대상으로 하는 알고리즘들을 공부하기 위해서는 이 각각이 무슨 뜻인지를 알고 있어야 합니다. 자, 그럼 트리를 이용하는 알고리즘을 공부할 준비가 되었나요? 다음 강의 (제 18 강) 에서는 가장 단순한 종류인 이진 트리 (binary tree) 부터 시작합니다.

#### 18강: 이진 트리(Binary Trees)



# 이진 트리 (Binary Trees)

이진 트리는, 트리에 포함되는 모든 노드의 차수가 2 이하인 트리를 말합니다. 즉, 모든 노드는 자식이 없거나 (리프 노드의 경우), 하나만 있거나, 아니면 둘 있는 세 경우 중 하나에 해당합니다.

우선은, 이진 트리를 추상적 자료 구조로 구현하기 위해서, 아래와 같은 연산을 생각해봅니다.

- size() - 현재 트리에 포함되어 있는 노드의 수를 구함
- depth() - 현재 트리의 깊이 (또는 높이) 를 구함

트리는 정의 자체가 재귀적이기 때문에, 이를 대상으로 하는 연산들도 대부분 재귀적으로 구현 가능합니다. 위 두 가지의 간단한 연산을 위한 코드를 살펴보고 연습문제로도 풀어봄으로써, 재귀적인 자료 구조가 (특히 트리가) 이러한 성질에 근거하여 얼마나 쓸모가 있게 되는지를 짐작해보시기 바랍니다.

트리의 각 노드를 정해진 순서로 방문하는 것을 순회 (traversal) 연산이라고 부릅니다. 트리를 순회하는 순서를 크게 나누면 깊이 우선 순회 (depth first traversal) 와 넓이 우선 순회 (breadth first traversal) 가 있습니다. 이 순회 방식들은 - 지난 강의에서 언급했듯이 우리 강의에서는 나아가지 않지만, 보다 일반적인 형태인 - 그래프에도 적용되는데, 많은 알고리즘들이 트리 또는 그래프의 순회를 이용하여 주어진 문제를 해결합니다.

이 중, 깊이 우선 순회가 보다 간단하므로 여기에서는 깊이 우선 순회를 먼저 알아보고, 다음 강의 (제 19 강) 에서 넓이 우선 순회도 알아봅시다.

깊이 우선 순회에도, 특히 이진 트리를 대상으로 하는 경우에는, 세 가지의 서로 다른 순서를 정의할 수 있습니다. 어느 노드 x 를 기준으로 할 때, (이 정의는 또 다시 재귀적임을 발견하세요)

- 중위 순회 (in-order traverasl): 왼쪽 서브트리를 순회한 뒤 노드 x 를 방문, 그리고 나서 오른쪽 서브트리를 순회
- 전위 순회 (pre-order traversal): 노드 x 를 방문한 후에 왼쪽 서브트리를 순회, 마지막으로 오른쪽 서브트리를 순회
- 후위 순회 (post-order traversal): 왼쪽 서브트리를 순회, 오른쪽 서브트리를 순회, 그리고 나서 마지막으로 노드 x 를 방문

하는 순서입니다. 이러한 순회 알고리즘 또한 (정의에서 느껴지는 바와 같이, 당연히) 재귀적으로 구현하는 것이 매우 자연스럽습니다. 중위 순회 알고리즘을 예제 코드로 보였습니다. 아주 조금만 바꾸면 나머지 둘, 즉 전위 순회와 후위 순회를 구현할 수 있습니다. 이 두 알고리즘은 연습문제로 풀어보세요.

#### 19강: 이진 트리 - 넓이 우선 순회(breadth first traversal)



# 이진 트리의 넓이 우선 순회 (BFS; Breadth First Traversal)

지난 강의 (제 18 강) 에서 남겨둔 하나의 순회 방법은 넓이 우선 순회입니다. 이것은 노드의 수준 (level - 기억하나요? 기억이 잘 나지 않으면 다시 제 17 강을 살짝 들여다 보세요) 에 따라 순서를 정하여 노드들을 방문하는 순회 방식입니다.

이 순회 방식도 재귀적으로 자연스럽게 구현되나요? 그렇지 않습니다. 하나의 노드를 방문했을 때, 나중에 그 노드의 자식 노드들을 방문하기로 해 두고, 같은 수준에 있는 다른 노드들 (직접 연결되어 있는 노드들이 아니에요!) 을 우선 방문해야 하기 때문에, 이 알고리즘은 재귀적인 성질을 가지지 않습니다.

그렇다면, 나중에 다시 방문하기로 하고 그 순서를 기억해 두자 에 적합한 자료 구조로서 우리가 알고 있는 것이 있나요?

있습니다. 제 14 강에서 배운 큐 (queue) 가 바로 그것입니다. 먼저 넣은 원소가 먼저 나오는, 선입선출 (FIFO; first-in first-out) 성질을 가지고 있기 때문에, 큐는 이러한 종류의 응용에 딱 적합합니다.

이 강의에서는 큐를 활용하여 주어진 이진 트리를 넓이 우선으로 순회하는 알고리즘을 함께 설계합니다. 구현은 연습문제입니다. 넓이 우선 순회에 어떻게 큐가 적용되는지, 그리고 이전에 (제 14 강에서) 구현해본 큐를 어떻게 다시 가져다가 활용하는지만 잘 이해하면, 어렵지 않게 넓이 우선 순회 알고리즘을 구현할 수 있습니다. 그러고 보니, 이제는 우리가 만들 수 있는 알고리즘의 수준이 처음에 비해서 꽤 높아진 것같은 기분이 드네요! 사실이 그렇습니다.

#### 20강: 이진 탐색 트리(Binary Search Trees) (1)



# 이진 탐색 트리 (Binary Search Trees)

이진 탐색 트리 (binary search tree) 는 이진 트리의 일종입니다. 그런데 이름이 낯설지를 않네요? 제 3 강에서 이진 탐색 (binary search) 알고리즘을 가볍게 다룬 적이 있습니다. 이진 탐색 알고리즘과 이진 탐색 트리를 이용한 탐색 알고리즘은 똑같은 것은 아닙니다. 하지만 많이 닮아 있습니다.

이진 탐색 알고리즘이 기억나나요? 이미 정렬된 선형 배열을 대상으로, 배열을 절반씩 잘라 가면서 찾고자 하는 원소 (또는 키 - key) 가 들어 있을 수 없음이 보장되는 절반을 탐색 대상에서 제외함으로써 매 반복에서 탐색 대상이 되는 배열의 길이를 반으로 만들어 나가는 알고리즘입니다. 따라서 이 알고리즘의 실행 시간은 배열의 길이를 `n` 이라고 할 때 `log(n)` (밑은 2 입니다) 에 비례합니다. 이진 탐색을 적용하기 위해서는 탐색 대상인 배열이 미리 정렬되어 있어야 하므로, 이 배열에 데이터 원소를 추가하거나 배열로부터 데이터 원소를 삭제하는 일은 `n` 에 비례하는 시간을 소요합니다.

이진 탐색 트리에서는, 모든 노드에 대해서 왼쪽 서브트리에 들어 있는 데이터는 모두 현재 노드의 값 (키) 보다 작고 오른쪽 서브트리에 들어 있는 데이터는 모두 현재 노드의 값 (키) 보다 크도록 트리를 유지합니다. 다시 말하면, 이러한 성질을 만족하는 이진 트리를 이진 탐색 트리라고 부릅니다.

탐색을 할 때는 루트 노드에서 시작해서 한 번에 한 단계씩 간선을 따라 아래로 아래로 내려갑니다. 어느 노드를 방문했을 때, 이 노드에 담긴 데이터 원소보다 찾고자 하는 키가 더 작은 경우에는 왼쪽 서브트리를, 더 큰 경우에는 오른쪽 서브트리를 택합니다. 반대쪽 서브트리에는 찾고자 하는 값이 없음을 보장할 수 있으니까 탐색할 필요가 없다는 성질을 이용하는 것이죠. 이렇게 해서 리프 노드에까지 이르렀는데도 그 사이에 찾고자 하는 값을 만나지 못하면 이 이진 탐색 트리에는 찾으려는 값이 없다는 것을 알 수 있습니다. 이 알고리즘에서도 뭔가 재귀적인 냄새가 나지 않나요? 당연합니다. 트리라는 자료 구조가 매우 재귀적인 성질을 가지고 있으니까요.

이 강의에서는 이진 탐색 트리를 추상적 자료 구조로 정의하는데, 아래와 같은 연산을 제공하도록 합니다.

- `insert()`: 트리에 주어진 데이터 원소를 추가
- `remove()`: 특정 원소를 트리로부터 삭제
- `lookup()`: 특정 원소를 검색 (탐색)
- `inorder()`: 키의 순서대로 데이터 원소들을 나열
- `min()`, `max()`: 최소 키, 최대 키를 가지는 원소를 각각 탐색

이 중 가장 중심이 되는 연산은 탐색 (lookup) 입니다. 이 연산의 실행 시간은 트리의 높이 (또는 깊이) 에 비례하므로, 평균적으로 (노드의 개수, 즉 데이터 원소의 개수를 `n` 이라 할 때) `log(n)` 에 비례합니다. 또한, 선형 배열이 아닌 트리 구조를 택하기 때문에 삽입/삭제 (insert/remove) 연산 또한 평균적으로 `log(n)` 에 비례하는 시간을 소요합니다. 왜 평균적 이라고 했냐면, 어떤 특수한 경우에 대해서는 이진 탐색 트리가 효과를 발휘할 수 없는 모습을 가지기 때문인데, 그 얘기는 다음 강의 (제 21 강) 에서 하겠습니다.

이번 강의에서는, 재귀적인 방법으로 위 연산들 중 `inorder()`, `min()`, `max()`, 그리고 `lookup()` 을 함께 구현해봅니다. 연습문제로는 `insert()` 를 구현하는 코딩을 실습합니다.

#### 21강: 이진 탐색 트리(Binary Search Trees) (2)



# 이진 탐색 트리 (Binary Search Trees)

지난 강의 (제 20 강) 에서 이진 탐색 트리 (binary search tree) 를 소개하고 아래와 같은 연산을 정의했습니다. (기억나나요?)

- insert(): 트리에 주어진 데이터 원소를 추가
- remove(): 특정 원소를 트리로부터 삭제
- lookup(): 특정 원소를 검색 (탐색)
- inorder(): 키의 순서대로 데이터 원소들을 나열
- min(), max(): 최소 키, 최대 키를 가지는 원소를 각각 탐색

이 중 `remove()` 를 제외한 연산들은 꽤 간단했습니다. 지난 강의에서 코드를 함께 검토하기도 했고, 연습문제로 풀어보기도 했습니다.

그런데, `remove()` 연산은 나머지 다른 연산들보다 조금 복잡합니다. 트리에서 리프 노드가 삭제되는 경우에는 별로 할 일이 많지 않지만, 루트 노드 또는 내부 노드가 삭제되는 경우에는 다른 노드들을 이리저리 옮겨서 트리의 모습을 갖추도록 구조를 조정해야 하기 때문입니다. 이 때, 삭제 연산이 끝난 이후의 트리도 (당연히) 이진 탐색 트리의 성질을 만족해야만 합니다. 다시 말하며, 이 연산을 구현할 때 트리를 조정함에 있어서 이진 탐색 트리의 모습을 유지하도록 알고리즘을 구성해야 한다는 뜻입니다.

자세한 알고리즘은 동영상 강의를 참고하세요. 이런 경우와 저런 경우 등을 나누어 생각해야 하기 때문에 알고리즘의 설계도 지금까지의 것들보다 조금 복잡하고, 코드의 구현도 이제는 조금 어려워진 느낌입니다. 하지만, 이 정도의 코드를 능숙하게 작성할 수 있다면, 이 강의에서 다루는 내용보다 더 발전된 알고리즘들 (제 17 강에서 언급한 바와 같이, 여러 종류의 트리와 이에 기반한 알고리즘들이 있어서 더욱 고급의 기능을 제공합니다) 을 설계, 구현할 수 있는 바탕이 마련되었을 것입니다. 연습문제로 코드를 직접 작성해 보세요. 지금쯤은 처음에 비해서 상당히 코딩 기술이 늘어 있음을 발견하게 되지 않나요?

이전 강의 (제 21 강) 에서, 이진 탐색 트리가 효과를 발휘할 수 없는 특수한 경우가 있다고 했습니다. 어떤 경우가 해당할까요? 만약 트리가 한 줄로 늘어서면 (즉, 모든 노드가 왼쪽 또는 오른쪽의 한 자식만을 가지는 경우) 노드의 개수가 `n` 이라 할 때 트리의 높이 (깊이) 또한 `n` 입니다. 이 경우 특정 원소를 탐색하면 이 탐색 연산의 복잡도는 선형 탐색 (linear search) 와 동일해집니다. 즉, 이진 탐색 트리를 애써 만들어 둔 것이 무색해지는 것이죠.

이 한계점은, 이진 탐색 트리에 원소를 삽입함에 있어서 높이를 최소화하려는, 즉 트리의 좌우 균형을 유지하려는 노력을 하지 않았기 때문입니다. 이런 한계를 극복하기 위해서 이진 탐색 트리에 추가의 제약을 (만족해야 하는 성질을) 부가한 트리들이 있습니다. 이 강의에서는 다루지 않지만, 이후 발전 학습을 원하는 경우 아래 트리들을 공부해 보세요.

- AVL trees
- Red-black trees

#### 22강: 힙(Heaps)



# 힙 (Heaps)

힙 (heap) 도 이진 트리의 한 종류입니다. 이진 힙 (binary heap) 이라고도 부릅니다. 힙은 데이터 원소들의 순서를 교묘하게 표현한 트리입니다. 따라서 데이터의 정렬에도 이용할 수 있는데, 힙을 이용하여 데이터를 정렬하는 알고리즘을 힙 정렬 (heap sort) 이라고 부릅니다.

힙에는 최대 힙 (max heap) 과 최소 힙 (min heap) 이 있습니다. 최대 힙과 최소 힙은 데이터 원소의 순서 기준이 내림차순이냐 오름차순이냐만 달라지고 완전히 대칭이므로, 여기에서는 최대 힙을 기준으로 설명을 전개하겠습니다. 최대 힙은 세 가지의 성질을 유지하고 있는 이진 트리입니다. 그 세 가지 성질은:

- 루트 노드가 항상 최댓값을 가진다.
- 완전 이진 트리이다.
- 최대 힙 내의 임의의 노드를 루트로 하는 서브트리 또한 최대 힙이다.

입니다. 마지막 성질은 트리에서 매우 자주 맞닥뜨리게 되는 재귀적인 정의네요.

앞에서 (제 20 강과 제 21 강에서) 살펴본 이진 탐색 트리 (binary search tree) 와 최대 힙은 조금 다른 특징을 가집니다. 이진 탐색 트리에서는 원소들이 완전히 크기 순서대로 정렬되어 있습니다. (따라서 중위 순회를 하면 데이터를 정렬된 순서로 뽑아낼 수 있습니다.) 최대 힙은 완전히 크기 순서대로 정렬되어 있지는 않습니다. (따라서 트리를 순회함으로써 데이터를 정렬할 수는 없습니다.) 또한, 이진 탐색 트리에서는 루트 노드로부터 시작하여 특정 원소를 빠르게 검색할 수 있는 반면, 최대 힙은 이러한 탐색 연산을 제공할 수 없습니다.

그렇다면 최대 힙의 장점은 무엇일까요? 바로 부가의 제약 조건, 즉 완전 이진 트리 (complete binary tree) 여야 한다는 제약 때문에, `n` 개의 노드로 이루어진 최대 힙의 높이 (깊이) 는 `log(n) + 1` (에서 소수 부분은 버림) 로 정해집니다. 이 성질 때문에 데이터 원소의 삽입/삭제 연산의 실행 시간은 언제나 `log(n)` 에 비례합니다. 따라서, 어떤 최대 힙이 존재할 때, 이 힙으로부터 반복적으로 루트 노드를 삭제하면 (서 데이터 원소들을 꺼내면) 루트 노드에 들어 있는 키가 힙 내에서 최대임이 보장되어 있으므로 데이터를 내림차순으로 정렬할 수 있고, 이 정렬에 소요되는 시간 또한 `log(n)` 에 비례합니다.

힙이 항상 완전 이진 트리라는 성질은 트리의 표현에 있어서도 이점을 제공합니다. (동영상 강의에서 소개될) 규칙에 따라 노드들에 번호를 매기면, 이 번호 순서로 이루어진 선형 배열에 트리를 표현할 수 있습니다. 또한, 완전 이진 트리이므로 노드의 추가와 삭제는 배열의 맨 마지막 원소에서만 일어납니다.

최대 힙을 추상적 자료 구조로 정의하고, 원소의 삽입 연산인 `insert()` 를 설명하겠습니다. 원소의 삽입은 맨 마지막 노드에서 일어나므로, 우선 맨 마지막 노드에 주어진 데이터를 임시로 붙인 뒤에 이 원소를 부모 노드의 키와 비교하여 더 큰 경우에는 그 부모와 위치를 맞바꿉니다. 이 과정을 루트 노드에 도달할 때까지 또는 더이상 맞바꿀 필요가 없을 때까지 반복하면 삽입이 완료됩니다. 그냥 말로 설명하면 얼핏 이해가 어렵게 느껴질 수 있습니다만, 동영상 강의에 포함된 예제 그림을 통해서 이해해보세요.

이제는 연습이 잘 되어 있어서 이런 정도의 코드는 어렵지 않게 작성할 수 있을 것으로 기대합니다. 연습 문제로 `insert()` 메서드를 작성해보세요.

#### 23강: 힙(Heaps) (2)



# 최대 힙 (Max Heap) 에서 원소의 삭제

앞선 제 21 강에서 경험했던 것처럼, 노드의 삭제는 삽입보다 다소 복잡합니다. 최대 힙 (max heap) 의 경우에도 그렇습니다. 이번 강의에서는 지난 강의 (제 22 강) 에서 정의한 최대 힙의 추상적 자료 구조에 원소 (노드) 의 삭제 연산을 추가해보겠습니다.

최대 힙에서의 원소 삭제는 항상 루트 노드에서 이루어집니다. 최댓값을 순서대로 뽑아 내는 데 관심이 있기 때문입니다. 이 연산을 반복 적용함으로써 데이터 정렬을 구현할 수 있다는 점은 이미 지난 강의 (제 22 강) 에서 설명한 바 있습니다. 그런데, 루트 노드를 삭제하고 나면 트리의 구조를 다시 정리해야 합니다. 앞서 (제 22 강에서) 언급한 것처럼, 노드의 삭제 또한 맨 마지막 노드에서만 일어납니다 (완전 이진 트리의 성질을 만족해야 하므로). 즉, 우선은 루트 노드의 데이터를 꺼내고, 맨 마지막 노드의 원소를 루트 노드의 자리에 임시로 집어넣습니다. 그 후, 마지막 노드를 제거한 다음에 루트 자리에 임시로 들어간 노드의 새로운 올바른 자리를 찾아 주면 됩니다.

노드의 삽입 연산에서와는 반대로, 이번에는 임시로 들어간 (일시적으로 위치가 올바르지 않은) 노드는 루트 노드에서 시작해서 아래로 아래로 내려갑니다. 자식들 중 더 큰 값을 가지는 노드와 자리를 바꾸면서, 더이상 바꿀 필요가 없거나 리프 노드에 도달할 때까지 이 과정을 반복합니다.

물론 이 자리 바꿈은 트리의 본질적인 성질에 기인하여 재귀적으로 구현될 수 있습니다. 그런데, 어느 노드에서 이 자리 바꿈을 행할 때의 코드 구현이 삽입의 경우보다 조금 복잡합니다. 왜냐면, 노드의 삽입에서는 자신의 부모 노드를 찾아서 자리를 바꿀지를 결정하는데 부모 노드는 오직 하나만 있거나 아니면 없는 (루트 노드의 경우) 데 비하여, 삭제 연산에서는 자식들 중 더 큰 키 값을 가지는 노드를 찾는데 자식이 둘 있는 경우, 하나만 있는 경우, 아니면 없는 경우 (리프 노드) 의 세 가지를 구별해서 생각해야 하기 때문입니다.

하지만 겁먹을 필요는 없습니다. 이미 우리는 (이 강의가 마지막 강의입니다) 코드 구현 연습을 꽤 탄탄하게 했고, 동영상 강의에서는 이 알고리즘을 보다 상세하게 설명합니다. 또한, 연습문제는 (그래도 조금 복잡하게 느껴지므로) 빈 칸 채우기 형태로 되어 있습니다.

마지막으로, 최대 힙을 이용하면 데이터의 정렬 이외에도 제 16 강에서 소개한 우선 순위 큐 (priority queue) 를 효과적으로 구현할 수 있음을 생각해보세요. Enqueue 할 때 느슨한 정렬 을 이루고 있도록 하고 (데이터를 완전히 순서대로 나열한 것과는 조금 다르죠?) dequeue 할 때 최댓값을 순서대로 꺼낼 수 있으며, 이 두 연산은 모두 (데이터의 개수가 `n` 이라고 할 때) `log(n)` 에 비례하는 복잡도를 가집니다.